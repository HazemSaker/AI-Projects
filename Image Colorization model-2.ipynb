{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f031c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Reshape, Conv2D, ReLU, LeakyReLU, UpSampling2D, BatchNormalization, Concatenate, Input, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, MeanAbsoluteError\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9f298c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r'C:\\Users\\Asus\\Desktop\\Others\\Datasets\\imagenet\\train'\n",
    "val_dir = r'C:\\Users\\Asus\\Desktop\\Others\\Datasets\\imagenet\\val'\n",
    "output_dir = r'C:\\Users\\Asus\\Desktop\\Others\\Datasets\\imagenet\\preproccessed'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52fae22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path, target_size=(256, 256)):\n",
    "    # Load image\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Resize with aspect ratio preservation\n",
    "    h, w = img.shape[:2]\n",
    "    scale = min(target_size[0]/h, target_size[1]/w)\n",
    "    new_h, new_w = int(h * scale), int(w * scale)\n",
    "    img_resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Pad to target size\n",
    "    delta_h = target_size[0] - new_h\n",
    "    delta_w = target_size[1] - new_w\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "    img_padded = cv2.copyMakeBorder(img_resized, top, bottom, left, right, \n",
    "                                   cv2.BORDER_REFLECT)\n",
    "    \n",
    "    # Convert to LAB color space\n",
    "    img_lab = color.rgb2lab(img_padded)\n",
    "    \n",
    "    # Normalize LAB values\n",
    "    img_lab = img_lab.astype('float32')\n",
    "    img_lab[..., 0] = img_lab[..., 0] / 100.0  # L channel [0,100] -> [0,1]\n",
    "    img_lab[..., 1:] = (img_lab[..., 1:] + 128) / 255.0  # ab channels [-128,127] -> [0,1]\n",
    "    \n",
    "    return img_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5b7e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(directory, output_path, batch_size=32, target_size=(256, 256)):\n",
    "    image_paths = [os.path.join(directory, f) for f in os.listdir(directory) \n",
    "                  if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    # Create output directories\n",
    "    os.makedirs(os.path.join(output_path, 'L'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_path, 'ab'), exist_ok=True)\n",
    "    \n",
    "    # Create processing log\n",
    "    log_file = os.path.join(output_path, 'processing_log.txt')\n",
    "    processed_indices = set()\n",
    "    \n",
    "    # Load existing log if resuming\n",
    "    if os.path.exists(log_file):\n",
    "        with open(log_file, 'r') as f:\n",
    "            processed_indices = {int(line.strip()) for line in f}\n",
    "    \n",
    "    for i in range(0, len(image_paths), batch_size):\n",
    "        batch_paths = image_paths[i:i+batch_size]\n",
    "        batch_images = []\n",
    "        valid_indices = []\n",
    "        \n",
    "        # Load and preprocess batch\n",
    "        for j, path in enumerate(batch_paths):\n",
    "            idx = i + j\n",
    "            if idx in processed_indices:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                img_lab = load_and_preprocess_image(path, target_size)\n",
    "                batch_images.append(img_lab)\n",
    "                valid_indices.append(idx)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {path}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if not batch_images:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            batch_images = np.array(batch_images)\n",
    "            \n",
    "            # Split into L and ab channels\n",
    "            L = batch_images[..., 0]\n",
    "            ab = batch_images[..., 1:]\n",
    "            \n",
    "            # Save batch with individual error handling\n",
    "            for j, idx in enumerate(valid_indices):\n",
    "                try:\n",
    "                    # Verify array contents before saving\n",
    "                    if not np.all(np.isfinite(L[j])):\n",
    "                        raise ValueError(\"L channel contains invalid values\")\n",
    "                    if not np.all(np.isfinite(ab[j])):\n",
    "                        raise ValueError(\"ab channels contain invalid values\")\n",
    "                        \n",
    "                    # Save with protocol=4 for better compatibility\n",
    "                    np.save(os.path.join(output_path, 'L', f'{idx}.npy'), L[j], allow_pickle=False)\n",
    "                    np.save(os.path.join(output_path, 'ab', f'{idx}.npy'), ab[j], allow_pickle=False)\n",
    "                    \n",
    "                    # Mark as processed\n",
    "                    with open(log_file, 'a') as f:\n",
    "                        f.write(f\"{idx}\\n\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to save image {idx}: {str(e)}\")\n",
    "                    # Clean up any partial files\n",
    "                    for fname in [f'{idx}.npy']:\n",
    "                        for subdir in ['L', 'ab']:\n",
    "                            file_path = os.path.join(output_path, subdir, fname)\n",
    "                            if os.path.exists(file_path):\n",
    "                                os.remove(file_path)\n",
    "                    continue\n",
    "                \n",
    "            print(f'Processed batch {i//batch_size + 1}/{(len(image_paths)//batch_size + 1)}')\n",
    "            \n",
    "        except Exception as batch_error:\n",
    "            print(f\"Batch processing failed: {str(batch_error)}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fbe4409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training data...\n",
      "Processed batch 1006/1407\n",
      "Processed batch 1007/1407\n",
      "Processed batch 1008/1407\n",
      "Processed batch 1009/1407\n",
      "Processed batch 1010/1407\n",
      "Processed batch 1011/1407\n",
      "Processed batch 1012/1407\n",
      "Processed batch 1013/1407\n",
      "Processed batch 1014/1407\n",
      "Processed batch 1015/1407\n",
      "Processed batch 1016/1407\n",
      "Processed batch 1017/1407\n",
      "Processed batch 1018/1407\n",
      "Processed batch 1019/1407\n",
      "Processed batch 1021/1407\n",
      "Processed batch 1022/1407\n",
      "Processed batch 1023/1407\n",
      "Processed batch 1024/1407\n",
      "Processed batch 1025/1407\n",
      "Processed batch 1026/1407\n",
      "Processed batch 1027/1407\n",
      "Processed batch 1028/1407\n",
      "Processed batch 1029/1407\n",
      "Processed batch 1030/1407\n",
      "Processed batch 1032/1407\n",
      "Processed batch 1033/1407\n",
      "Processed batch 1034/1407\n",
      "Processed batch 1035/1407\n",
      "Processed batch 1036/1407\n",
      "Processed batch 1037/1407\n",
      "Processed batch 1038/1407\n",
      "Processed batch 1040/1407\n",
      "Processed batch 1041/1407\n",
      "Processed batch 1042/1407\n",
      "Processed batch 1043/1407\n",
      "Processed batch 1044/1407\n",
      "Processed batch 1045/1407\n",
      "Processed batch 1046/1407\n",
      "Processed batch 1047/1407\n",
      "Processed batch 1048/1407\n",
      "Processed batch 1049/1407\n",
      "Processed batch 1050/1407\n",
      "Processed batch 1051/1407\n",
      "Processed batch 1052/1407\n",
      "Processed batch 1053/1407\n",
      "Processed batch 1054/1407\n",
      "Processed batch 1055/1407\n",
      "Processed batch 1056/1407\n",
      "Processed batch 1057/1407\n",
      "Processed batch 1058/1407\n",
      "Processed batch 1059/1407\n",
      "Processed batch 1060/1407\n",
      "Processed batch 1061/1407\n",
      "Processed batch 1062/1407\n",
      "Processed batch 1063/1407\n",
      "Processed batch 1064/1407\n",
      "Processed batch 1065/1407\n",
      "Processed batch 1066/1407\n",
      "Processed batch 1067/1407\n",
      "Processed batch 1068/1407\n",
      "Processed batch 1069/1407\n",
      "Processed batch 1070/1407\n",
      "Processed batch 1071/1407\n",
      "Processed batch 1072/1407\n",
      "Processed batch 1073/1407\n",
      "Processed batch 1074/1407\n",
      "Processed batch 1075/1407\n",
      "Processed batch 1076/1407\n",
      "Processed batch 1077/1407\n",
      "Processed batch 1078/1407\n",
      "Processed batch 1079/1407\n",
      "Processed batch 1080/1407\n",
      "Processed batch 1081/1407\n",
      "Processed batch 1082/1407\n",
      "Processed batch 1083/1407\n",
      "Processed batch 1084/1407\n",
      "Processed batch 1085/1407\n",
      "Processed batch 1086/1407\n",
      "Processed batch 1087/1407\n",
      "Processed batch 1088/1407\n",
      "Processed batch 1089/1407\n",
      "Processed batch 1090/1407\n",
      "Processed batch 1091/1407\n",
      "Processed batch 1092/1407\n",
      "Processed batch 1093/1407\n",
      "Processed batch 1094/1407\n",
      "Processed batch 1095/1407\n",
      "Processed batch 1096/1407\n",
      "Processed batch 1097/1407\n",
      "Processed batch 1098/1407\n",
      "Processed batch 1099/1407\n",
      "Processed batch 1100/1407\n",
      "Processed batch 1101/1407\n",
      "Processed batch 1102/1407\n",
      "Processed batch 1103/1407\n",
      "Processed batch 1104/1407\n",
      "Processed batch 1105/1407\n",
      "Processed batch 1106/1407\n",
      "Processed batch 1107/1407\n",
      "Processed batch 1108/1407\n",
      "Processed batch 1109/1407\n",
      "Processed batch 1110/1407\n",
      "Processed batch 1111/1407\n",
      "Processed batch 1112/1407\n",
      "Processed batch 1113/1407\n",
      "Processed batch 1114/1407\n",
      "Processed batch 1115/1407\n",
      "Processed batch 1116/1407\n",
      "Processed batch 1117/1407\n",
      "Processed batch 1118/1407\n",
      "\n",
      "Processing validation data...\n"
     ]
    }
   ],
   "source": [
    "# Process training data\n",
    "print(\"Processing training data...\")\n",
    "process_dataset(train_dir, os.path.join(output_dir, 'train'))\n",
    "\n",
    "# Process validation data\n",
    "print(\"\\nProcessing validation data...\")\n",
    "process_dataset(val_dir, os.path.join(output_dir, 'val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e6449aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data_dir, batch_size=32):\n",
    "    L_dir = os.path.join(data_dir, 'L')\n",
    "    ab_dir = os.path.join(data_dir, 'ab')\n",
    "    \n",
    "    L_files = sorted([os.path.join(L_dir, f) for f in os.listdir(L_dir)])\n",
    "    ab_files = sorted([os.path.join(ab_dir, f) for f in os.listdir(ab_dir)])\n",
    "    \n",
    "    while True:\n",
    "        for i in range(0, len(L_files), batch_size):\n",
    "            batch_L = []\n",
    "            batch_ab = []\n",
    "            \n",
    "            for L_path, ab_path in zip(L_files[i:i+batch_size], ab_files[i:i+batch_size]):\n",
    "                batch_L.append(np.load(L_path))\n",
    "                batch_ab.append(np.load(ab_path))\n",
    "            \n",
    "            yield np.array(batch_L), np.array(batch_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a042aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_generator():\n",
    "    inputs = Input(shape=(256, 256))\n",
    "    \n",
    "    x = Reshape((256, 256, 1))(inputs)\n",
    "    \n",
    "    # Encoder Path\n",
    "    d1 = Conv2D(64, 4, strides=2, padding='same')(x)\n",
    "    d1 = LeakyReLU(0.2)(d1)\n",
    "    \n",
    "    d2 = Conv2D(128, 4, strides=2, padding='same')(d1)\n",
    "    d2 = BatchNormalization()(d2)\n",
    "    d2 = LeakyReLU(0.2)(d2)\n",
    "    \n",
    "    # Bottleneck\n",
    "    bottleneck = Conv2D(256, 3, padding='same')(d2)\n",
    "    bottleneck = Conv2D(256, 3, padding='same')(bottleneck)\n",
    "    \n",
    "    # Decoder Path with Skip Connections\n",
    "    u1 = UpSampling2D(2)(bottleneck)  \n",
    "    u1 = Concatenate()([u1, d1])      # Skip connection from d1\n",
    "    u1 = Conv2D(128, 3, padding='same')(u1)\n",
    "    u1 = ReLU()(u1)\n",
    "    \n",
    "    u2 = UpSampling2D(2)(u1)      \n",
    "    u2 = Concatenate()([u2, x])       # Skip connection from reshaped input\n",
    "    u2 = Conv2D(64, 3, padding='same')(u2)\n",
    "    u2 = ReLU()(u2)\n",
    "    \n",
    "    outputs = Conv2D(2, 3, activation='tanh', padding='same')(u2)\n",
    "    \n",
    "    return Model(inputs, outputs, name='EnhancedGenerator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a87bca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(input_shape=(256, 256, 3)):\n",
    "   \n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = Conv2D(64, 4, strides=2, padding='same')(inputs)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(128, 4, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(256, 4, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(512, 4, strides=1, padding='same')(x)  \n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(1, 4, strides=1, padding='same')(x)\n",
    "    outputs = Activation('sigmoid')(x)\n",
    "    \n",
    "    return Model(inputs, outputs, name='ColorizationDiscriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "38283c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Generator Verification\n",
      "==================================================\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step\n",
      "\n",
      "Generator output shape: (1, 256, 256, 2)\n",
      "\n",
      "==================================================\n",
      "Discriminator Verification\n",
      "==================================================\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "\n",
      "Real prediction shape: (1, 32, 32, 1)\n",
      "\n",
      "==================================================\n",
      "GAN Integration Check\n",
      "==================================================\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step\n",
      "\n",
      "GAN outputs: (1, 256, 256, 2), (1, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "def verify_gan_components():\n",
    "    generator = enhanced_generator()\n",
    "    discriminator = build_discriminator()\n",
    "   \n",
    "    print(\"=\"*50)\n",
    "    print(\"Generator Verification\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    dummy_l = np.random.random((1, 256, 256, 1))\n",
    "    generated_ab = generator.predict(dummy_l)\n",
    "    print(f\"\\nGenerator output shape: {generated_ab.shape}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Discriminator Verification\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    real_image = np.concatenate([dummy_l, np.random.uniform(-1, 1, (1, 256, 256, 2))], axis=-1)\n",
    "    real_pred = discriminator.predict(real_image)\n",
    "    print(f\"\\nReal prediction shape: {real_pred.shape}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"GAN Integration Check\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    discriminator.trainable = False\n",
    "    input_l = Input(shape=(256, 256, 1))\n",
    "    gan_ab = generator(input_l)\n",
    "    merged = Concatenate(axis=-1)([input_l, gan_ab]) \n",
    "    gan_output = discriminator(merged)\n",
    "    gan = Model(input_l, [gan_ab, gan_output])\n",
    "    \n",
    "    gan_ab_pred, gan_disc_pred = gan.predict(dummy_l)\n",
    "    print(f\"\\nGAN outputs: {gan_ab_pred.shape}, {gan_disc_pred.shape}\")\n",
    "\n",
    "verify_gan_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4909236a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Step 0/2813\n",
      "D Loss: 0.7787 | G Loss: 38.8656 [Adv: 0.7027, L1: 38.1628]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 62\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps_per_epoch):\n\u001b[0;32m     61\u001b[0m     real_L, real_ab \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(train_gen)\n\u001b[1;32m---> 62\u001b[0m     d_loss, g_loss, g_adv, g_l1 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_L\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_ab\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Log progress every 50 steps\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    868\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generator = enhanced_generator()\n",
    "discriminator = build_discriminator(input_shape=(256, 256, 3))\n",
    "\n",
    "# Optimizers\n",
    "gen_optimizer = Adam(learning_rate=1e-4, beta_1=0.5)\n",
    "disc_optimizer = Adam(learning_rate=1e-5, beta_1=0.5)\n",
    "\n",
    "# Loss functions\n",
    "bce_loss = BinaryCrossentropy()\n",
    "l1_loss = MeanAbsoluteError()\n",
    "lambda_l1 = 100  # L1 loss weight\n",
    "\n",
    "# Data generator setup\n",
    "data_dir = r\"C:\\Users\\Asus\\Desktop\\Others\\Datasets\\imagenet\\preproccessed\\train\"  # Update with your directory\n",
    "batch_size = 16\n",
    "train_gen = data_generator(data_dir, batch_size=batch_size)\n",
    "\n",
    "# Calculate steps per epoch\n",
    "num_train_files = len(os.listdir(os.path.join(data_dir, 'L')))\n",
    "steps_per_epoch = (num_train_files + batch_size - 1) // batch_size\n",
    "\n",
    "@tf.function\n",
    "def train_step(real_L, real_ab):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # Generate fake ab channels\n",
    "        fake_ab = generator(real_L, training=True)\n",
    "        \n",
    "        # Create Lab images (real and fake)\n",
    "        real_L_expanded = tf.expand_dims(real_L, axis=-1)  # (bs, 256,256,1)\n",
    "        real_Lab = tf.concat([real_L_expanded, real_ab], axis=-1)\n",
    "        fake_Lab = tf.concat([real_L_expanded, fake_ab], axis=-1)\n",
    "        \n",
    "        # Discriminator predictions\n",
    "        pred_real = discriminator(real_Lab, training=True)\n",
    "        pred_fake = discriminator(fake_Lab, training=True)\n",
    "        \n",
    "        # Discriminator loss\n",
    "        disc_loss_real = bce_loss(tf.ones_like(pred_real), pred_real)\n",
    "        disc_loss_fake = bce_loss(tf.zeros_like(pred_fake), pred_fake)\n",
    "        disc_total_loss = (disc_loss_real + disc_loss_fake) * 0.5\n",
    "        \n",
    "        # Generator losses\n",
    "        gen_adv_loss = bce_loss(tf.ones_like(pred_fake), pred_fake)\n",
    "        gen_l1 = l1_loss(real_ab, fake_ab) * lambda_l1\n",
    "        gen_total_loss = gen_adv_loss + gen_l1\n",
    "\n",
    "    # Update discriminator\n",
    "    disc_grads = tape.gradient(disc_total_loss, discriminator.trainable_variables)\n",
    "    disc_optimizer.apply_gradients(zip(disc_grads, discriminator.trainable_variables))\n",
    "    \n",
    "    # Update generator\n",
    "    gen_grads = tape.gradient(gen_total_loss, generator.trainable_variables)\n",
    "    gen_optimizer.apply_gradients(zip(gen_grads, generator.trainable_variables))\n",
    "    \n",
    "    return disc_total_loss, gen_total_loss, gen_adv_loss, gen_l1\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    for step in range(steps_per_epoch):\n",
    "        real_L, real_ab = next(train_gen)\n",
    "        d_loss, g_loss, g_adv, g_l1 = train_step(real_L, real_ab)\n",
    "        \n",
    "        # Log progress every 50 steps\n",
    "        if step % 50 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} | Step {step}/{steps_per_epoch}\")\n",
    "            print(f\"D Loss: {d_loss:.4f} | G Loss: {g_loss:.4f} [Adv: {g_adv:.4f}, L1: {g_l1:.4f}]\")\n",
    "    \n",
    "    # Save model and sample images every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        generator.save(f\"generator_epoch_{epoch+1}.h5\")\n",
    "        print(f\"Saved checkpoint at epoch {epoch+1}\")\n",
    "\n",
    "# Save final model\n",
    "generator.save(\"generator_final.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
